{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "from jiwer import cer\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, GPT2Tokenizer, GPT2Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained tokenizer and model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-960h').to(device)\n",
    "\n",
    "# GPT2\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 128\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "      <th>faces</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s03e20-000128</td>\n",
       "      <td>chandler</td>\n",
       "      <td>Wait a minute, wait. You’re telling me this ac...</td>\n",
       "      <td>[[[800, 257, 870, 342], joey], [[543, 259, 597...</td>\n",
       "      <td>s03e20-000063-000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s03e20-000218</td>\n",
       "      <td>joey</td>\n",
       "      <td>Yeah! Oh my God! (to Chandler) Is this what it...</td>\n",
       "      <td>[[[797, 242, 863, 326], joey], [[532, 250, 593...</td>\n",
       "      <td>s03e20-000194-000320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s03e20-000538</td>\n",
       "      <td>joey</td>\n",
       "      <td>Oh, you have no idea. And-and when we’re on st...</td>\n",
       "      <td>[[[567, 79, 787, 358], joey]]</td>\n",
       "      <td>s03e20-000403-000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s03e20-000680</td>\n",
       "      <td>phoebe</td>\n",
       "      <td>to see you feeling like this!</td>\n",
       "      <td>[[[428, 74, 657, 353], phoebe]]</td>\n",
       "      <td>s03e20-000646-000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s03e20-000832</td>\n",
       "      <td>ross</td>\n",
       "      <td>Monica, uh Dad called this morning and ah, Aun...</td>\n",
       "      <td>[[[472, 396, 545, 491], phoebe], [[133, 134, 2...</td>\n",
       "      <td>s03e20-000820-000957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           frame   speaker                                            content  \\\n",
       "0  s03e20-000128  chandler  Wait a minute, wait. You’re telling me this ac...   \n",
       "1  s03e20-000218      joey  Yeah! Oh my God! (to Chandler) Is this what it...   \n",
       "2  s03e20-000538      joey  Oh, you have no idea. And-and when we’re on st...   \n",
       "3  s03e20-000680    phoebe                      to see you feeling like this!   \n",
       "4  s03e20-000832      ross  Monica, uh Dad called this morning and ah, Aun...   \n",
       "\n",
       "                                               faces                 video  \n",
       "0  [[[800, 257, 870, 342], joey], [[543, 259, 597...  s03e20-000063-000194  \n",
       "1  [[[797, 242, 863, 326], joey], [[532, 250, 593...  s03e20-000194-000320  \n",
       "2                      [[[567, 79, 787, 358], joey]]  s03e20-000403-000639  \n",
       "3                    [[[428, 74, 657, 353], phoebe]]  s03e20-000646-000715  \n",
       "4  [[[472, 396, 545, 491], phoebe], [[133, 134, 2...  s03e20-000820-000957  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_file = r\"C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\5_turns\\test-metadata.json\"\n",
    "with open(annotations_file, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "    annotations = list(itertools.chain.from_iterable(annotations))\n",
    "    \n",
    "annotations = pd.DataFrame(annotations)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "      <th>faces</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>s03e16-007283</td>\n",
       "      <td>phoebe</td>\n",
       "      <td>Now what is Fabutec?</td>\n",
       "      <td>[[[815, 69, 907, 202], phoebe], [[441, 108, 51...</td>\n",
       "      <td>s03e16-007258-007295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>s03e18-020687</td>\n",
       "      <td>pete</td>\n",
       "      <td>Hang on a second. (to the employees) I’ll-I’ll...</td>\n",
       "      <td>[]</td>\n",
       "      <td>s03e18-020628-020694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>s03e03-023600</td>\n",
       "      <td>phoebe</td>\n",
       "      <td>Look, he gave me his night vision goggles and ...</td>\n",
       "      <td>[[[664, 82, 810, 297], phoebe]]</td>\n",
       "      <td>s03e03-023561-023639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>s03e23-027540</td>\n",
       "      <td>pete</td>\n",
       "      <td>Yeah. Monica, I want you there in the front ro...</td>\n",
       "      <td>[[[326, 57, 593, 376], pete], [[672, 108, 884,...</td>\n",
       "      <td>s03e23-027382-027623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>s03e25-019235</td>\n",
       "      <td>bonnie</td>\n",
       "      <td>Oh, the water was sooo great! We jumped off th...</td>\n",
       "      <td>[[[554, 42, 727, 293], bonnie]]</td>\n",
       "      <td>s03e25-019182-019288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              frame speaker  \\\n",
       "7160  s03e16-007283  phoebe   \n",
       "2225  s03e18-020687    pete   \n",
       "6883  s03e03-023600  phoebe   \n",
       "5663  s03e23-027540    pete   \n",
       "9976  s03e25-019235  bonnie   \n",
       "\n",
       "                                                content  \\\n",
       "7160                               Now what is Fabutec?   \n",
       "2225  Hang on a second. (to the employees) I’ll-I’ll...   \n",
       "6883  Look, he gave me his night vision goggles and ...   \n",
       "5663  Yeah. Monica, I want you there in the front ro...   \n",
       "9976  Oh, the water was sooo great! We jumped off th...   \n",
       "\n",
       "                                                  faces                 video  \n",
       "7160  [[[815, 69, 907, 202], phoebe], [[441, 108, 51...  s03e16-007258-007295  \n",
       "2225                                                 []  s03e18-020628-020694  \n",
       "6883                    [[[664, 82, 810, 297], phoebe]]  s03e03-023561-023639  \n",
       "5663  [[[326, 57, 593, 376], pete], [[672, 108, 884,...  s03e23-027382-027623  \n",
       "9976                    [[[554, 42, 727, 293], bonnie]]  s03e25-019182-019288  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_frames = annotations.sample(num_of_samples, random_state=57)\n",
    "random_frames.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = []\n",
    "actual_transcripts = []\n",
    "\n",
    "for index, row in random_frames.iterrows():\n",
    "    episode, t1, t2 = row[\"video\"].split(\"-\")\n",
    "    audio_file = Path(\n",
    "        f\"C:\\\\Users\\\\a_has\\\\Desktop\\\\Friends\\\\friends_mmc\\\\face_track_videos\\\\face_track_videos\\\\{episode}\\\\{t1}-{t2}\\\\0.wav\"\n",
    "    ).resolve()\n",
    "    audio_paths.append(audio_file)\n",
    "    actual_transcripts.append(\n",
    "        row[\"content\"]\n",
    "        .strip()\n",
    "        .lower()\n",
    "        .replace(\",\", \"\")\n",
    "        .replace(\".\", \"\")\n",
    "        .replace(\"?\", \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, len(audio_paths), batch_size)):\n",
    "    batch_files = audio_paths[i : i + batch_size]\n",
    "    batch_actual_transcripts = actual_transcripts[i : i + batch_size]\n",
    "    \n",
    "    waveforms = []\n",
    "    max_length = 0  # Track max waveform length\n",
    "\n",
    "    # Load and resample audio files\n",
    "    for audio_file in batch_files:\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        if sample_rate != 16000:\n",
    "            transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "            waveform = transform(waveform)\n",
    "\n",
    "        waveform = waveform.squeeze(0)  # Remove extra dimension\n",
    "        waveforms.append(waveform)\n",
    "        max_length = max(max_length, waveform.shape[0])  # Find max length in batch\n",
    "\n",
    "    # Pad all waveforms to max_length\n",
    "    padded_waveforms = []\n",
    "    for waveform in waveforms:\n",
    "        pad_length = max_length - waveform.shape[0]\n",
    "        padded_waveform = torch.nn.functional.pad(waveform, (4000, pad_length)) # right_pad + fix left_pad\n",
    "        padded_waveforms.append(padded_waveform)\n",
    "\n",
    "    # Convert list of tensors to a batch tensor\n",
    "    batch_waveforms = torch.stack(padded_waveforms)\n",
    "\n",
    "    # Convert list of waveforms to a batch tensor with padding\n",
    "    input_values = processor(batch_waveforms.numpy(), return_tensors=\"pt\", padding=True, sampling_rate=16000)[\"input_values\"]\n",
    "\n",
    "    # Step 3: Perform model inference in batch\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Step 4: Decode predictions in batch\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcriptions = processor.batch_decode(predicted_ids)\n",
    "\n",
    "    # Step 5: Compute similarity metrics\n",
    "    for j, transcription in enumerate(transcriptions):\n",
    "        gen_text = transcription.strip().lower()\n",
    "        actual_text = batch_actual_transcripts[j]\n",
    "\n",
    "        def get_gpt2_embedding(text):\n",
    "            if not text.strip():  # Check if the text is empty\n",
    "                return torch.zeros(1, 768)  # Return a zero vector with GPT-2 embedding size (768)\n",
    "            inputs = gpt2_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = gpt2_model(**inputs)\n",
    "            return outputs.last_hidden_state.mean(dim=1)  # Get mean-pooled embedding\n",
    "        \n",
    "        actual_embedding = get_gpt2_embedding(actual_text)\n",
    "        gen_embedding = get_gpt2_embedding(gen_text)\n",
    "\n",
    "        cosine_sim = cosine_similarity(actual_embedding.numpy(), gen_embedding.numpy())[0][0]\n",
    "        cer_score = cer(actual_text, gen_text)\n",
    "\n",
    "        results.append({\n",
    "            \"audio_file\": batch_files[j],\n",
    "            \"actual_transcript\": actual_text,\n",
    "            \"generated_transcript\": gen_text,\n",
    "            \"CER\": cer_score,\n",
    "            \"GPT-2 Cosine Similarity\": cosine_sim\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>actual_transcript</th>\n",
       "      <th>generated_transcript</th>\n",
       "      <th>CER</th>\n",
       "      <th>GPT-2 Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...</td>\n",
       "      <td>you really really need to get some sleep honey</td>\n",
       "      <td>im in to get them slave i know</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.994691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...</td>\n",
       "      <td>yeah monica i want you there in the front row ...</td>\n",
       "      <td>monica i want ye there in the front roll when ...</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.999420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...</td>\n",
       "      <td>dude i don’t know</td>\n",
       "      <td>to that don't kno</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.991003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...</td>\n",
       "      <td>(looking at the timer) thirty seconds left on ...</td>\n",
       "      <td>if i can sup on the time o</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.992553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...</td>\n",
       "      <td>you know we don’t really take advantage of liv...</td>\n",
       "      <td>no we really don't take advanage liieg in the ...</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.997531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           audio_file  \\\n",
       "49  C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...   \n",
       "3   C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...   \n",
       "24  C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...   \n",
       "78  C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...   \n",
       "52  C:\\Users\\a_has\\Desktop\\Friends\\friends_mmc\\fac...   \n",
       "\n",
       "                                    actual_transcript  \\\n",
       "49     you really really need to get some sleep honey   \n",
       "3   yeah monica i want you there in the front row ...   \n",
       "24                                  dude i don’t know   \n",
       "78  (looking at the timer) thirty seconds left on ...   \n",
       "52  you know we don’t really take advantage of liv...   \n",
       "\n",
       "                                 generated_transcript       CER  \\\n",
       "49                     im in to get them slave i know  0.695652   \n",
       "3   monica i want ye there in the front roll when ...  0.119658   \n",
       "24                                  to that don't kno  0.529412   \n",
       "78                         if i can sup on the time o  0.660714   \n",
       "52  no we really don't take advanage liieg in the ...  0.393443   \n",
       "\n",
       "    GPT-2 Cosine Similarity  \n",
       "49                 0.994691  \n",
       "3                  0.999420  \n",
       "24                 0.991003  \n",
       "78                 0.992553  \n",
       "52                 0.997531  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CER                        0.537633\n",
       "GPT-2 Cosine Similarity    0.880790\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Character Error Rate (CER): Measures character-level errors\n",
    "mean_values = df_results[[\"CER\", \"GPT-2 Cosine Similarity\"]].mean()\n",
    "display(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in random_frames.iterrows():\n",
    "#     episode, t1, t2 = row[\"video\"].split(\"-\")\n",
    "#     audio_file = Path(f\"C:\\\\Users\\\\a_has\\\\Desktop\\\\Friends\\\\friends_mmc\\\\face_track_videos\\\\face_track_videos\\\\{episode}\\\\{t1}-{t2}\\\\0.wav\")\n",
    "\n",
    "#     waveform, sample_rate = torchaudio.load(audio_file)\n",
    "#     if sample_rate != 16000:\n",
    "#         transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "#         waveform = transform(waveform)\n",
    "\n",
    "#     input_values = processor(waveform.numpy(), return_tensors=\"pt\", sampling_rate=16000)[\"input_values\"]\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(input_values).logits\n",
    "#     predicted_ids = torch.argmax(logits, dim=-1)\n",
    "#     transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "#     print(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
