{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "from jiwer import cer\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, GPT2Tokenizer, GPT2Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained tokenizer and model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-960h').to(device)\n",
    "\n",
    "# GPT2\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 1024\n",
    "batch_size = 4\n",
    "random_seed = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_350.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_184.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_068.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_007.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_381.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_355.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_036.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_311.txt\n",
      "Missing audio file for: C:\\Users\\a_has\\Desktop\\DS_10283_3443\\txt\\p362\\p362_085.txt\n"
     ]
    }
   ],
   "source": [
    "audio_paths = []\n",
    "actual_transcripts = []\n",
    "\n",
    "# Base directories\n",
    "text_base_dir = Path(\"C:\\\\Users\\\\a_has\\\\Desktop\\\\DS_10283_3443\\\\txt\")\n",
    "audio_base_dir = Path(\"C:\\\\Users\\\\a_has\\\\Desktop\\\\DS_10283_3443\\\\wav48_silence_trimmed\")\n",
    "\n",
    "# Collect all text files across all subfolders\n",
    "all_text_files = []\n",
    "for subfolder in text_base_dir.iterdir():\n",
    "    if subfolder.is_dir():\n",
    "        text_files = list(subfolder.glob(\"*.txt\"))\n",
    "        for text_file in text_files:\n",
    "            all_text_files.append((subfolder.name, text_file))\n",
    "\n",
    "random.seed(random_seed)\n",
    "selected_files = random.sample(all_text_files, min(num_of_samples, len(all_text_files)))\n",
    "\n",
    "# Process the selected files\n",
    "for speaker_id, text_file in selected_files:\n",
    "    with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().strip().lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"?\", \"\")\n",
    "\n",
    "    # Construct the corresponding audio file path\n",
    "    audio_filename = text_file.stem + \"_mic1.flac\"\n",
    "    audio_file = audio_base_dir / speaker_id / audio_filename\n",
    "\n",
    "    # Append to lists if the audio file exists\n",
    "    if audio_file.exists():\n",
    "        audio_paths.append(audio_file.resolve())\n",
    "        actual_transcripts.append(content)\n",
    "    else:\n",
    "        print(f\"Missing audio file for: {text_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [15:10<00:00,  3.59s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, len(audio_paths), batch_size)):\n",
    "    batch_files = audio_paths[i : i + batch_size]\n",
    "    batch_actual_transcripts = actual_transcripts[i : i + batch_size]\n",
    "    \n",
    "    waveforms = []\n",
    "    max_length = 0  # Track max waveform length\n",
    "\n",
    "    # Load and resample audio files\n",
    "    for audio_file in batch_files:\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        if sample_rate != 16000:\n",
    "            transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "            waveform = transform(waveform)\n",
    "\n",
    "        waveform = waveform.squeeze(0)  # Remove extra dimension\n",
    "        waveforms.append(waveform)\n",
    "        max_length = max(max_length, waveform.shape[0])  # Find max length in batch\n",
    "\n",
    "    # Pad all waveforms to max_length\n",
    "    padded_waveforms = []\n",
    "    for waveform in waveforms:\n",
    "        pad_length = max_length - waveform.shape[0]\n",
    "        padded_waveform = torch.nn.functional.pad(waveform, (4000, pad_length)) # right_pad + fix left_pad\n",
    "        padded_waveforms.append(padded_waveform)\n",
    "\n",
    "    # Convert list of tensors to a batch tensor\n",
    "    batch_waveforms = torch.stack(padded_waveforms)\n",
    "\n",
    "    # Convert list of waveforms to a batch tensor with padding\n",
    "    input_values = processor(batch_waveforms.numpy(), return_tensors=\"pt\", padding=True, sampling_rate=16000)[\"input_values\"]\n",
    "\n",
    "    # Step 3: Perform model inference in batch\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Step 4: Decode predictions in batch\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcriptions = processor.batch_decode(predicted_ids)\n",
    "\n",
    "    # Step 5: Compute similarity metrics\n",
    "    for j, transcription in enumerate(transcriptions):\n",
    "        gen_text = transcription.strip().lower()\n",
    "        actual_text = batch_actual_transcripts[j]\n",
    "\n",
    "        def get_gpt2_embedding(text):\n",
    "            if not text.strip():  # Check if the text is empty\n",
    "                return torch.zeros(1, 768)  # Return a zero vector with GPT-2 embedding size (768)\n",
    "            inputs = gpt2_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = gpt2_model(**inputs)\n",
    "            return outputs.last_hidden_state.mean(dim=1)  # Get mean-pooled embedding\n",
    "        \n",
    "        actual_embedding = get_gpt2_embedding(actual_text)\n",
    "        gen_embedding = get_gpt2_embedding(gen_text)\n",
    "\n",
    "        cosine_sim = cosine_similarity(actual_embedding.numpy(), gen_embedding.numpy())[0][0]\n",
    "        cer_score = cer(actual_text, gen_text)\n",
    "\n",
    "        results.append({\n",
    "            \"audio_file\": batch_files[j],\n",
    "            \"actual_transcript\": actual_text,\n",
    "            \"generated_transcript\": gen_text,\n",
    "            \"CER\": cer_score,\n",
    "            \"GPT-2 Cosine Similarity\": cosine_sim\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>actual_transcript</th>\n",
       "      <th>generated_transcript</th>\n",
       "      <th>CER</th>\n",
       "      <th>GPT-2 Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p314\\p314_125_mic1.flac</td>\n",
       "      <td>but it will backfire</td>\n",
       "      <td>but it will back fire</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.999678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p236\\p236_261_mic1.flac</td>\n",
       "      <td>he also launched a new strategy for the agency</td>\n",
       "      <td>he also launched new stratagy for the agency</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.997225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p279\\p279_092_mic1.flac</td>\n",
       "      <td>they lived for their children</td>\n",
       "      <td>they lived for their children</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p240\\p240_164_mic1.flac</td>\n",
       "      <td>however the french government has a major dilemma on its hands</td>\n",
       "      <td>however the french government has a major dilemma on its hands</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p286\\p286_051_mic1.flac</td>\n",
       "      <td>he also presented you bet!</td>\n",
       "      <td>he also presented yeu bet</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.998713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             audio_file  \\\n",
       "899  C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p314\\p314_125_mic1.flac   \n",
       "410  C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p236\\p236_261_mic1.flac   \n",
       "251  C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p279\\p279_092_mic1.flac   \n",
       "346  C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p240\\p240_164_mic1.flac   \n",
       "160  C:\\Users\\a_has\\Desktop\\DS_10283_3443\\wav48_silence_trimmed\\p286\\p286_051_mic1.flac   \n",
       "\n",
       "                                                  actual_transcript  \\\n",
       "899                                            but it will backfire   \n",
       "410                  he also launched a new strategy for the agency   \n",
       "251                                   they lived for their children   \n",
       "346  however the french government has a major dilemma on its hands   \n",
       "160                                      he also presented you bet!   \n",
       "\n",
       "                                               generated_transcript       CER  \\\n",
       "899                                           but it will back fire  0.050000   \n",
       "410                    he also launched new stratagy for the agency  0.065217   \n",
       "251                                   they lived for their children  0.000000   \n",
       "346  however the french government has a major dilemma on its hands  0.000000   \n",
       "160                                       he also presented yeu bet  0.076923   \n",
       "\n",
       "     GPT-2 Cosine Similarity  \n",
       "899                 0.999678  \n",
       "410                 0.997225  \n",
       "251                 1.000000  \n",
       "346                 1.000000  \n",
       "160                 0.998713  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df_results.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CER                        0.032010\n",
       "GPT-2 Cosine Similarity    0.999332\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Character Error Rate (CER): Measures character-level errors\n",
    "mean_values = df_results[[\"CER\", \"GPT-2 Cosine Similarity\"]].mean()\n",
    "display(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in random_frames.iterrows():\n",
    "#     episode, t1, t2 = row[\"video\"].split(\"-\")\n",
    "#     audio_file = Path(f\"C:\\\\Users\\\\a_has\\\\Desktop\\\\Friends\\\\friends_mmc\\\\face_track_videos\\\\face_track_videos\\\\{episode}\\\\{t1}-{t2}\\\\0.wav\")\n",
    "\n",
    "#     waveform, sample_rate = torchaudio.load(audio_file)\n",
    "#     if sample_rate != 16000:\n",
    "#         transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "#         waveform = transform(waveform)\n",
    "\n",
    "#     input_values = processor(waveform.numpy(), return_tensors=\"pt\", sampling_rate=16000)[\"input_values\"]\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(input_values).logits\n",
    "#     predicted_ids = torch.argmax(logits, dim=-1)\n",
    "#     transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "#     print(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
